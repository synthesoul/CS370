{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "from TreasureMaze import TreasureMaze\n",
    "from GameExperience import GameExperience\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maze = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [0., 1., 0., 1.],\n",
    "    [0., 1., 0., 1.],\n",
    "    [1., 1., 1., 1.]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Q-Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(maze):\n",
    "    input_size = maze.size\n",
    "    output_size = 4  # LEFT, UP, RIGHT, DOWN\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(InputLayer(input_shape=(input_size,)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(output_size, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(qmaze):\n",
    "    print(qmaze.draw_env())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Check Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def completion_check(model, qmaze):\n",
    "    for cell in qmaze.free_cells:\n",
    "        qmaze.reset(cell)\n",
    "        envstate = qmaze.observe()\n",
    "        game_over = False\n",
    "        steps = 0\n",
    "        while not game_over and steps < 100:\n",
    "            q = model.predict(envstate)[0]\n",
    "            q = [q[a] if a in qmaze.valid_actions() else -np.inf for a in range(4)]\n",
    "            action = int(np.argmax(q))\n",
    "            envstate, _, game_status = qmaze.act(action)\n",
    "            game_over = (game_status != 'not_over')\n",
    "            steps += 1\n",
    "        if game_status != 'win':\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Formatting Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(seconds):\n",
    "    if seconds < 400:\n",
    "        return \"%.1f seconds\" % seconds\n",
    "    elif seconds < 4000:\n",
    "        return \"%.2f minutes\" % (seconds / 60.0)\n",
    "    else:\n",
    "        return \"%.2f hours\" % (seconds / 3600.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qtrain(model, maze, **opt):\n",
    "    global epsilon\n",
    "    n_epoch = opt.get('epochs', 15000)\n",
    "    max_memory = opt.get('max_memory', 1000)\n",
    "    data_size = opt.get('data_size', 50)\n",
    "\n",
    "    qmaze = TreasureMaze(maze)\n",
    "    experience = GameExperience(model, max_memory=max_memory)\n",
    "\n",
    "    start_time = datetime.datetime.now()\n",
    "    win_history = []\n",
    "    hsize = qmaze.maze.size // 2\n",
    "    win_rate = 0.0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        loss = 0.0\n",
    "        n_episodes = 0\n",
    "\n",
    "        agent_cell = random.choice(qmaze.free_cells)\n",
    "        qmaze.reset(agent_cell)\n",
    "        envstate = qmaze.observe()\n",
    "        game_over = False\n",
    "\n",
    "        while not game_over:\n",
    "            valid_actions = qmaze.valid_actions()\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = random.choice(valid_actions)\n",
    "            else:\n",
    "                q = experience.predict(envstate)\n",
    "                q = [q[a] if a in valid_actions else -np.inf for a in range(4)]\n",
    "                action = int(np.argmax(q))\n",
    "\n",
    "            prev_envstate = envstate\n",
    "            envstate, reward, game_status = qmaze.act(action)\n",
    "            game_over = (game_status != 'not_over')\n",
    "\n",
    "            episode = [prev_envstate, action, reward, envstate, game_over]\n",
    "            experience.remember(episode)\n",
    "\n",
    "            inputs, targets = experience.get_data(data_size=data_size)\n",
    "            h = model.fit(inputs, targets, epochs=1, verbose=0)\n",
    "            loss += h.history['loss'][0]\n",
    "\n",
    "        n_episodes += 1\n",
    "        win_history.append(1 if game_status == 'win' else 0)\n",
    "        if len(win_history) > hsize:\n",
    "            del win_history[0]\n",
    "        win_rate = sum(win_history) / len(win_history)\n",
    "\n",
    "        dt = datetime.datetime.now() - start_time\n",
    "        t = format_time(dt.total_seconds())\n",
    "        print(f\"Epoch: {epoch:03d}/{n_epoch - 1} | Loss: {loss:.4f} | Episodes: {n_episodes} | Win count: {sum(win_history)} | Win rate: {win_rate:.3f} | time: {t}\")\n",
    "\n",
    "        if win_rate > 0.9:\n",
    "            epsilon = 0.05\n",
    "\n",
    "        if sum(win_history[-hsize:]) == hsize and completion_check(model, qmaze):\n",
    "            print(\"Reached 100% win rate at epoch:\", epoch)\n",
    "            break\n",
    "\n",
    "    total_time = datetime.datetime.now() - start_time\n",
    "    print(\"Training completed in:\", format_time(total_time.total_seconds()))\n",
    "    print(f\"n_epoch: {epoch}, max_mem: {max_memory}, data: {data_size}\")\n",
    "    return total_time.total_seconds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/999 | Loss: 0.6997 | Episodes: 1 | Win count: 1 | Win rate: 1.000 | time: 11.8 seconds\n",
      "Epoch: 001/999 | Loss: 0.9511 | Episodes: 1 | Win count: 1 | Win rate: 0.500 | time: 83.5 seconds\n",
      "Epoch: 002/999 | Loss: 0.1846 | Episodes: 1 | Win count: 2 | Win rate: 0.667 | time: 118.1 seconds\n",
      "Epoch: 003/999 | Loss: 0.0441 | Episodes: 1 | Win count: 3 | Win rate: 0.750 | time: 124.9 seconds\n",
      "Epoch: 004/999 | Loss: 0.6479 | Episodes: 1 | Win count: 4 | Win rate: 0.800 | time: 208.4 seconds\n",
      "Epoch: 005/999 | Loss: 0.3412 | Episodes: 1 | Win count: 5 | Win rate: 0.833 | time: 261.5 seconds\n",
      "Epoch: 006/999 | Loss: 0.0448 | Episodes: 1 | Win count: 6 | Win rate: 0.857 | time: 268.4 seconds\n",
      "Epoch: 007/999 | Loss: 0.0641 | Episodes: 1 | Win count: 7 | Win rate: 0.875 | time: 278.3 seconds\n",
      "Epoch: 008/999 | Loss: 0.1515 | Episodes: 1 | Win count: 7 | Win rate: 0.875 | time: 290.5 seconds\n",
      "Epoch: 009/999 | Loss: 0.1381 | Episodes: 1 | Win count: 8 | Win rate: 1.000 | time: 297.9 seconds\n",
      "Reached 100% win rate at epoch: 9\n",
      "Training completed in: 299.1 seconds\n",
      "n_epoch: 9, max_mem: 128, data: 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "299.052286"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epsilon = 1.0\n",
    "model = build_model(maze)\n",
    "qtrain(model, maze, epochs=1000, max_memory=8 * maze.size, data_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Completion Check & Maze Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'maze' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-95017f846656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mqmaze\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTreasureMaze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaze\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcompletion_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqmaze\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqmaze\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'maze' is not defined"
     ]
    }
   ],
   "source": [
    "qmaze = TreasureMaze(maze)\n",
    "completion_check(model, qmaze)\n",
    "show(qmaze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
